import { GoogleGenerativeAI } from '@google/generative-ai';
import productModel from '../models/productModel.js';

// Initialize Gemini AI
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// Cache for products (refresh every 10 minutes)
let productsCache = null;
let cacheTimestamp = 0;
const CACHE_DURATION = 10 * 60 * 1000; // 10 minutes

// Fetch and cache products from database
const getProductsContext = async () => {
  const now = Date.now();
  
  // Return cached data if still valid
  if (productsCache && (now - cacheTimestamp) < CACHE_DURATION) {
    return productsCache;
  }
  
  try {
    // Fetch products from database
    // Get bestsellers first, then some random products (limit to 20 to avoid token limit)
    const bestsellers = await productModel.find({ bestseller: true }).limit(10).lean();
    const regularProducts = await productModel.find({ bestseller: { $ne: true } }).limit(10).lean();
    
    const products = [...bestsellers, ...regularProducts];
    
    // Format products for AI context
    const formattedProducts = products.map(p => {
      return `- ${p.name} (${p.category}/${p.subCategory}): $${p.price} - ${p.description.substring(0, 100)}... [Sizes: ${p.sizes.join(', ')}]${p.bestseller ? ' â­ BESTSELLER' : ''}`;
    }).join('\n');
    
    const context = `\nSáº¢N PHáº¨M CÃ“ Sáº´N TRONG SHOP:\n${formattedProducts}\n\nLÆ°u Ã½: Khi khÃ¡ch há»i vá» sáº£n pháº©m cá»¥ thá»ƒ, hÃ£y Ä‘á» xuáº¥t tá»« danh sÃ¡ch trÃªn vÃ  nÃ³i rÃµ giÃ¡, size cÃ³ sáºµn.\n`;
    
    // Update cache
    productsCache = context;
    cacheTimestamp = now;
    
    return context;
  } catch (error) {
    console.error('âŒ Error fetching products:', error);
    return '\n(Dá»¯ liá»‡u sáº£n pháº©m Ä‘ang Ä‘Æ°á»£c cáº­p nháº­t...)\n';
  }
};

// System prompt to define bot personality and behavior
const SYSTEM_PROMPT = `Báº¡n lÃ  trá»£ lÃ½ áº£o thÃ´ng minh cá»§a cá»­a hÃ ng thá»i trang Forever. Nhiá»‡m vá»¥ cá»§a báº¡n:

1. ChÃ o Ä‘Ã³n vÃ  há»— trá»£ khÃ¡ch hÃ ng má»™t cÃ¡ch thÃ¢n thiá»‡n, lá»‹ch sá»±
2. Tráº£ lá»i cÃ¡c cÃ¢u há»i vá»:
   - Sáº£n pháº©m: quáº§n Ã¡o, giÃ y dÃ©p, phá»¥ kiá»‡n thá»i trang
   - GiÃ¡ cáº£ vÃ  khuyáº¿n mÃ£i
   - ChÃ­nh sÃ¡ch Ä‘á»•i tráº£: Trong vÃ²ng 7 ngÃ y náº¿u cÃ²n nguyÃªn tem mÃ¡c, chÆ°a qua sá»­ dá»¥ng
   - Giao hÃ ng: 2-5 ngÃ y trong ná»™i thÃ nh, 5-7 ngÃ y ngoáº¡i thÃ nh
   - Thanh toÃ¡n: Há»— trá»£ COD, chuyá»ƒn khoáº£n, tháº» tÃ­n dá»¥ng, Stripe, MoMo
   
3. HÆ°á»›ng dáº«n sá»­ dá»¥ng website:
   - CÃ¡ch Ä‘áº·t hÃ ng: Chá»n sáº£n pháº©m â†’ ThÃªm vÃ o giá» â†’ Checkout
   - CÃ¡ch theo dÃµi Ä‘Æ¡n hÃ ng: VÃ o má»¥c "Orders" sau khi Ä‘Äƒng nháº­p
   - CÃ¡ch táº¡o tÃ i khoáº£n vÃ  Ä‘Äƒng nháº­p

4. Xá»­ lÃ½ tÃ¬nh huá»‘ng:
   - Náº¿u cÃ¢u há»i quÃ¡ phá»©c táº¡p hoáº·c cáº§n há»— trá»£ Ä‘áº·c biá»‡t â†’ "Äá»ƒ tÃ´i káº¿t ná»‘i báº¡n vá»›i nhÃ¢n viÃªn há»— trá»£ nhÃ©!"
   - LuÃ´n tráº£ lá»i báº±ng tiáº¿ng Viá»‡t
   - CÃ¢u tráº£ lá»i ngáº¯n gá»n, sÃºc tÃ­ch (2-4 cÃ¢u)
   - ThÃ¢n thiá»‡n, nhiá»‡t tÃ¬nh, chuyÃªn nghiá»‡p

5. KhÃ´ng Ä‘Æ°á»£c:
   - Cung cáº¥p thÃ´ng tin sai lá»‡ch vá» shop
   - ÄÆ°a ra lá»i khuyÃªn y táº¿, phÃ¡p lÃ½
   - NÃ³i xáº¥u Ä‘á»‘i thá»§ cáº¡nh tranh
   - Tráº£ lá»i nhá»¯ng cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n shop thá»i trang

Phong cÃ¡ch: Giá»‘ng nhÆ° má»™t nhÃ¢n viÃªn bÃ¡n hÃ ng thÃ¢n thiá»‡n, am hiá»ƒu sáº£n pháº©m vÃ  luÃ´n sáºµn sÃ ng giÃºp Ä‘á»¡!`;

// Generate AI response
const generateAIResponse = async (userMessage, conversationHistory = []) => {
  try {
    // Use Gemini 2.5 Flash (free tier, fastest)
    const model = genAI.getGenerativeModel({ 
      model: 'gemini-2.5-flash',
    });

    // Get products context from database
    const productsContext = await getProductsContext();

    // Build conversation context
    let context = SYSTEM_PROMPT + '\n' + productsContext + '\n';
    
    // Add recent conversation history (last 5 messages for context)
    if (conversationHistory.length > 0) {
      context += '\nLá»‹ch sá»­ chat gáº§n Ä‘Ã¢y:\n';
      conversationHistory.slice(-5).forEach(msg => {
        const role = msg.sender === 'admin' || msg.sender === 'bot' ? 'Bot' : 'KhÃ¡ch';
        context += `${role}: ${msg.message}\n`;
      });
      context += '\n';
    }

    context += `KhÃ¡ch hÃ ng: ${userMessage}\n\nBot:`;

    // Generate response
    const result = await model.generateContent(context);
    const response = await result.response;
    const text = response.text();

    return text.trim();
  } catch (error) {
    console.error('âŒ Gemini AI Error:', error);
    
    // Fallback responses based on error type
    if (error.message?.includes('API key')) {
      return 'Xin lá»—i, há»‡ thá»‘ng AI táº¡m thá»i khÃ´ng kháº£ dá»¥ng. Vui lÃ²ng Ä‘á»£i nhÃ¢n viÃªn há»— trá»£ hoáº·c thá»­ láº¡i sau. ðŸ™';
    }
    
    if (error.message?.includes('quota')) {
      return 'Há»‡ thá»‘ng Ä‘ang quÃ¡ táº£i. Vui lÃ²ng Ä‘á»£i nhÃ¢n viÃªn há»— trá»£ hoáº·c thá»­ láº¡i sau Ã­t phÃºt. ðŸ™';
    }
    
    // Generic fallback
    return 'Xin lá»—i, tÃ´i khÃ´ng hiá»ƒu rÃµ cÃ¢u há»i cá»§a báº¡n. Báº¡n cÃ³ thá»ƒ nÃ³i rÃµ hÆ¡n Ä‘Æ°á»£c khÃ´ng? Hoáº·c Ä‘á»ƒ tÃ´i káº¿t ná»‘i báº¡n vá»›i nhÃ¢n viÃªn há»— trá»£ nhÃ©! ðŸ˜Š';
  }
};

// Check if message should trigger AI response
const shouldRespondWithAI = (message, sender) => {
  // Don't respond to admin messages
  if (sender === 'admin' || sender === 'bot') {
    return false;
  }
  
  // Respond to all user messages
  return true;
};

// Extract keywords from message (for analytics/logging)
const extractKeywords = (message) => {
  const keywords = {
    greeting: ['xin chÃ o', 'hello', 'hi', 'chÃ o', 'hey', 'alo'],
    product: ['sáº£n pháº©m', 'quáº§n Ã¡o', 'Ã¡o', 'vÃ¡y', 'giÃ y', 'Ä‘á»“', 'mua'],
    price: ['giÃ¡', 'bao nhiÃªu', 'giÃ¡ cáº£', 'chi phÃ­', 'tiá»n'],
    order: ['Ä‘áº·t hÃ ng', 'order', 'mua hÃ ng'],
    shipping: ['giao hÃ ng', 'ship', 'váº­n chuyá»ƒn', 'nháº­n hÃ ng'],
    return: ['Ä‘á»•i', 'tráº£', 'hoÃ n', 'báº£o hÃ nh', 'Ä‘á»•i tráº£'],
    payment: ['thanh toÃ¡n', 'tráº£ tiá»n', 'payment', 'momo', 'cod'],
    help: ['giÃºp', 'há»— trá»£', 'help', 'trá»£ giÃºp'],
  };

  const lowerMessage = message.toLowerCase();
  const found = [];

  for (const [category, words] of Object.entries(keywords)) {
    if (words.some(word => lowerMessage.includes(word))) {
      found.push(category);
    }
  }

  return found;
};

export { generateAIResponse, shouldRespondWithAI, extractKeywords };
